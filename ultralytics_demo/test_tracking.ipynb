{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac2f5ed-ed6e-4909-92a0-fc31fa76b9ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T23:01:22.058833Z",
     "iopub.status.busy": "2023-09-30T23:01:22.058299Z",
     "iopub.status.idle": "2023-09-30T23:01:22.711983Z",
     "shell.execute_reply": "2023-09-30T23:01:22.711652Z",
     "shell.execute_reply.started": "2023-09-30T23:01:22.058804Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javkhlan-ochirganbat/.venv/dev_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8114afbd-de3f-462c-8e58-62b8a66f77ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T23:01:27.893370Z",
     "iopub.status.busy": "2023-09-30T23:01:27.892645Z",
     "iopub.status.idle": "2023-09-30T23:01:28.004815Z",
     "shell.execute_reply": "2023-09-30T23:01:28.004542Z",
     "shell.execute_reply.started": "2023-09-30T23:01:27.893341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load an official or custom model\n",
    "model = YOLO('yolov8n.pt')  # Load an official Detect model\n",
    "model = YOLO('yolov8n-seg.pt')  # Load an official Segment model\n",
    "model = YOLO('yolov8n-pose.pt')  # Load an official Pose model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1fc75a4-5bd0-4498-bf97-2ff916ee331a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T23:01:31.414802Z",
     "iopub.status.busy": "2023-09-30T23:01:31.414174Z",
     "iopub.status.idle": "2023-09-30T23:01:52.922592Z",
     "shell.execute_reply": "2023-09-30T23:01:52.922037Z",
     "shell.execute_reply.started": "2023-09-30T23:01:31.414774Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.6ms\n",
      "video 1/1 (2/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.7ms\n",
      "video 1/1 (3/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.2ms\n",
      "video 1/1 (4/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (5/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.5ms\n",
      "video 1/1 (6/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (7/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (8/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.0ms\n",
      "video 1/1 (9/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.3ms\n",
      "video 1/1 (10/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (11/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.8ms\n",
      "video 1/1 (12/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.6ms\n",
      "video 1/1 (13/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.8ms\n",
      "video 1/1 (14/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (15/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (16/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.6ms\n",
      "video 1/1 (17/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (18/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.0ms\n",
      "video 1/1 (19/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (20/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (21/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.7ms\n",
      "video 1/1 (22/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.2ms\n",
      "video 1/1 (23/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (24/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (25/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (26/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.0ms\n",
      "video 1/1 (27/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.1ms\n",
      "video 1/1 (28/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.0ms\n",
      "video 1/1 (29/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.0ms\n",
      "video 1/1 (30/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (31/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (32/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.8ms\n",
      "video 1/1 (33/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (34/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (35/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (36/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.2ms\n",
      "video 1/1 (37/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (38/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.0ms\n",
      "video 1/1 (39/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (40/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.0ms\n",
      "video 1/1 (41/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.8ms\n",
      "video 1/1 (42/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.8ms\n",
      "video 1/1 (43/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (44/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (45/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (46/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.8ms\n",
      "video 1/1 (47/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (48/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (49/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (50/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.1ms\n",
      "video 1/1 (51/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (52/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.1ms\n",
      "video 1/1 (53/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.0ms\n",
      "video 1/1 (54/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (55/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (56/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (57/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (58/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (59/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (60/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (61/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.2ms\n",
      "video 1/1 (62/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 42.2ms\n",
      "video 1/1 (63/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (64/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (65/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.8ms\n",
      "video 1/1 (66/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (67/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.3ms\n",
      "video 1/1 (68/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (69/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (70/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (71/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (72/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (73/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.3ms\n",
      "video 1/1 (74/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (75/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.3ms\n",
      "video 1/1 (76/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.2ms\n",
      "video 1/1 (77/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (78/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (79/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (80/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (81/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (82/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (83/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (84/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (85/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (86/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (87/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (88/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (89/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (90/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (91/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (92/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (93/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (94/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (95/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (96/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (97/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (98/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (99/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.3ms\n",
      "video 1/1 (100/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (101/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (102/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (103/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (104/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (105/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (106/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (107/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (108/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (109/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (110/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (111/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (112/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (113/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.2ms\n",
      "video 1/1 (114/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (115/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (116/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (117/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (118/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.1ms\n",
      "video 1/1 (119/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (120/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (121/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (122/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (123/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (124/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (125/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (126/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (127/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (128/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 42.9ms\n",
      "video 1/1 (129/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (130/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (131/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (132/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (133/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (134/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (135/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 39.0ms\n",
      "video 1/1 (136/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (137/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.6ms\n",
      "video 1/1 (138/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (139/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 39.9ms\n",
      "video 1/1 (140/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 39.3ms\n",
      "video 1/1 (141/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (142/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (143/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (144/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (145/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (146/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (147/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (148/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (149/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (150/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 39.3ms\n",
      "video 1/1 (151/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 39.0ms\n",
      "video 1/1 (152/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (153/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 38.9ms\n",
      "video 1/1 (154/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (155/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (156/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.6ms\n",
      "video 1/1 (157/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (158/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (159/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (160/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 38.9ms\n",
      "video 1/1 (161/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 39.3ms\n",
      "video 1/1 (162/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 1 person, 39.6ms\n",
      "video 1/1 (163/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.3ms\n",
      "video 1/1 (164/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (165/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (166/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (167/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (168/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 43.4ms\n",
      "video 1/1 (169/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (170/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (171/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (172/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (173/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (174/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (175/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (176/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.1ms\n",
      "video 1/1 (177/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (178/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (179/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (180/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (181/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (182/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.5ms\n",
      "video 1/1 (183/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (184/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (185/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (186/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (187/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (188/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (189/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (190/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (191/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (192/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (193/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (194/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.7ms\n",
      "video 1/1 (195/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (196/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.1ms\n",
      "video 1/1 (197/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.7ms\n",
      "video 1/1 (198/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (199/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (200/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (201/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (202/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.3ms\n",
      "video 1/1 (203/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (204/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (205/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (206/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (207/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (208/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (209/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (210/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (211/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (212/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (213/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 42.6ms\n",
      "video 1/1 (214/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (215/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (216/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (217/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (218/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (219/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (220/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (221/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (222/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (223/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (224/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (225/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.8ms\n",
      "video 1/1 (226/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (227/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (228/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (229/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (230/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (231/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (232/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.3ms\n",
      "video 1/1 (233/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (234/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (235/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (236/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (237/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (238/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (239/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (240/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.0ms\n",
      "video 1/1 (241/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (242/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.3ms\n",
      "video 1/1 (243/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (244/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (245/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (246/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (247/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.0ms\n",
      "video 1/1 (248/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (249/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (250/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (251/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.2ms\n",
      "video 1/1 (252/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 43.7ms\n",
      "video 1/1 (253/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (254/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.3ms\n",
      "video 1/1 (255/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (256/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (257/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (258/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (259/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (260/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.8ms\n",
      "video 1/1 (261/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (262/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (263/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (264/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (265/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (266/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (267/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (268/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (269/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (270/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.8ms\n",
      "video 1/1 (271/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (272/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (273/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.2ms\n",
      "video 1/1 (274/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (275/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (276/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (277/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (278/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (279/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (280/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (281/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (282/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (283/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.0ms\n",
      "video 1/1 (284/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (285/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.9ms\n",
      "video 1/1 (286/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (287/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 41.7ms\n",
      "video 1/1 (288/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.3ms\n",
      "video 1/1 (289/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.6ms\n",
      "video 1/1 (290/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.8ms\n",
      "video 1/1 (291/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (292/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (293/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (294/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (295/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (296/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (297/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (298/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (299/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 44.6ms\n",
      "video 1/1 (300/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (301/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (302/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (303/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (304/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (305/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (306/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (307/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (308/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (309/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (310/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (311/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (312/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (313/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (314/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (315/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (316/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (317/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (318/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (319/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (320/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (321/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.8ms\n",
      "video 1/1 (322/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 42.0ms\n",
      "video 1/1 (323/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (324/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (325/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (326/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.2ms\n",
      "video 1/1 (327/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.8ms\n",
      "video 1/1 (328/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.1ms\n",
      "video 1/1 (329/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (330/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.0ms\n",
      "video 1/1 (331/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (332/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (333/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (334/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (335/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (336/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (337/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (338/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (339/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (340/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.1ms\n",
      "video 1/1 (341/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.3ms\n",
      "video 1/1 (342/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (343/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (344/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (345/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.8ms\n",
      "video 1/1 (346/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.4ms\n",
      "video 1/1 (347/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.5ms\n",
      "video 1/1 (348/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.2ms\n",
      "video 1/1 (349/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (350/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (351/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (352/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (353/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (354/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (355/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (356/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 38.4ms\n",
      "video 1/1 (357/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (358/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.0ms\n",
      "video 1/1 (359/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.8ms\n",
      "video 1/1 (360/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.6ms\n",
      "video 1/1 (361/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 43.6ms\n",
      "video 1/1 (362/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (363/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (364/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (365/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (366/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (367/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (368/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (369/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.6ms\n",
      "video 1/1 (370/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (371/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 39.9ms\n",
      "video 1/1 (372/2684) /Users/javkhlan-ochirganbat/repos/machine-learning/ultralytics_demo/baby_shrimps.mp4: 384x640 (no detections), 40.0ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = YOLO('path/to/best.pt')  # Load a custom trained model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Perform tracking with the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# results = model.track(source=\"https://youtu.be/LNwODJXcvt4\", show=True)  # Tracking with default tracker\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# results = model.track(source=\"https://youtu.be/LNwODJXcvt4\", show=True, tracker=\"bytetrack.yaml\")  # Tracking with ByteTrack tracker\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./baby_shrimps.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Tracking with ByteTrack tracker\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/engine/model.py:255\u001b[0m, in \u001b[0;36mModel.track\u001b[0;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconf\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# ByteTrack-based method needs low confidence predictions as input\u001b[39;00m\n\u001b[1;32m    254\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/engine/model.py:235\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/engine/predictor.py:194\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/torch/autograd/grad_mode.py:64\u001b[0m, in \u001b[0;36m_DecoratorContextManager._wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 64\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/engine/predictor.py:253\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 253\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/engine/predictor.py:133\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minference\u001b[39m(\u001b[38;5;28mself\u001b[39m, im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    131\u001b[0m     visualize \u001b[38;5;241m=\u001b[39m increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem,\n\u001b[1;32m    132\u001b[0m                                mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:339\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize)\u001b[0m\n\u001b[1;32m    336\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize) \u001b[38;5;28;01mif\u001b[39;00m augment \u001b[38;5;129;01mor\u001b[39;00m visualize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/nn/tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/nn/tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/nn/tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m---> 82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m     83\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py:42\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/dev_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = YOLO('path/to/best.pt')  # Load a custom trained model\n",
    "\n",
    "# Perform tracking with the model\n",
    "# results = model.track(source=\"https://youtu.be/LNwODJXcvt4\", show=True)  # Tracking with default tracker\n",
    "# results = model.track(source=\"https://youtu.be/LNwODJXcvt4\", show=True, tracker=\"bytetrack.yaml\")  # Tracking with ByteTrack tracker\n",
    "results = model.track(source=\"./baby_shrimps.mp4\", show=True, tracker=\"bytetrack.yaml\")  # Tracking with ByteTrack tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486dbecc-0421-4373-bbfa-538023f6491b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "dev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
